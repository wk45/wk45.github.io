# Hierarchical Latent SVD Model

As an extended idea of latent distance models (LDM), the latent eigenmodel was introduced to capture both homophily and stochastic equivalence among nodes. The main difference between LDMs and eigenmodels is the choice of the function dependent on the latent space. More specifically, eigenmodels use $a(u_i,u_j) = u_i^T\Lambda u_j$ instead of mere physical distance function. Besides, all latent class, distance and eigenmodels only deal with the symmetric function $d$ or $a$. However; the function also can be asymmetric if there exist sender and receiver effects are different. It is so-called SVD model, and the model specification is as follows:

$$\text{logit}P(Y_{ij}=1) = \beta^TX_{ij} + a_i + b_j + u_i^Tv_j + 
\epsilon_{ij}$$

where $u$ and $v$ are vectors of latent nodal attributes, and $a_i$ and $b_i$ are terms for nodal heterogeneity.

## MCMC Derivation

\begin{align*}
\mathbf{Y}_{ijk} &= \mathbb{1}_{[\mathbf{Z}_{ijk}>0]}\\
\mathbf{Z}_{ijk} &= \sum_{p=0}^{P}\beta_{pk}^T\mathbf{X}_{ijpk} + a_{ik} + b_{jk} + u_{ik}^Tv_{jk} + \epsilon_{ijk}\\
(a_{ik}, b_{ik}) &\stackrel{iid}{\sim} MVN_2((0,0), \mathbf{\Sigma}_{ab})\\
(u_{ik}, v_{ik}) &\stackrel{iid}{\sim} MVN_4((0,0,0,0), \mathbf{\Sigma}_{uv})\\
(\epsilon_{ijk}, \epsilon_{jik}) &\stackrel{iid}{\sim} MVN_2\Big( 
  \begin{pmatrix} 0 \\ 0 \end{pmatrix},\begin{pmatrix} 1 & \rho_k \\ \rho_k & 1 \end{pmatrix}\Big)\\
\beta_{p}  &\sim N(\mu_p, \sigma_p^2)\\
\mu_p  &\sim N(\lambda, \tau^2)\\
\sigma_p^2  &\sim IG(\nu_0, S_0)\\
\mathbf{\Sigma}_{ab} &\sim IWishart(\nu_{ab},S_{ab}^{-1})\\
\mathbf{\Sigma}_{uv} &\sim IWishart(\nu_{uv},S_{uv}^{-1})\\
\end{align*}

### Update $Z_{ijk}, Z_{jik}$:

\begin{align*}
(\mathbf{Z}_{ijk}, \mathbf{Z}_{jik}) &\stackrel{iid}{\sim} MVN_2\Big( 
  \begin{pmatrix} \sum_{p=0}^{P}\mathbf{X}_{ijpk}\beta_{pk} + a_{ik} + b_{jk} + u_{ik}^Tv_{jk} \\ \sum_{p=0}^{P}\mathbf{X}_{ijpk}\beta_{pk} + a_{jk} + b_{ik} + u_{jk}^Tv_{ik} \end{pmatrix},\begin{pmatrix} 1 & \rho_k \\ \rho_k & 1 \end{pmatrix}\Big)\\
\end{align*}

Let $\eta_{ijk} = \sum_{p=0}^{P}\mathbf{X}_{ijpk}\beta_{pk} + a_{ik} + b_{jk} + u_{ik}^Tv_{jk}$

\begin{align*}
\mathbf{Z}_{ijk}\mid \mathbf{Z}_{jik} &\sim N(\eta_{ijk} + \rho_k\cdot(\mathbf{Z}_{jik} - \eta_{jik}), 1 - \rho_k^2)\\
\\
\text{Pr}(\mathbf{Z}_{ijk} \mid  \mathbf{Z}_{jik}, \mathbf{Y}_{ijk} = 1, \cdots) &\propto \text{Pr}(\mathbf{Y}_{ijk} = 1 \mid  \cdots) \cdot \text{Pr}(\mathbf{Z}_{ijk} \mid  \mathbf{\mathbf{Z}}_{jik})\\
&= \left\{
\begin{array}{c l}  
     \mathbb{1}_{[\mathbf{Z}_{ijk} > 1]} \cdot dN(\mathbf{Z}_{ijk}; \eta_{ijk} + \rho_k\cdot(\mathbf{Z}_{jik} - \eta_{jik}), 1 - \rho_k^2 ) \text{ if } Y_{ijk} = 1\\
     \mathbb{1}_{[\mathbf{Z}_{ijk} < 1]} \cdot dN(\mathbf{Z}_{ijk}; \eta_{ijk} + \rho_k\cdot(\mathbf{Z}_{jik} - \eta_{jik}), 1 - \rho_k^2 ) \text{ if } Y_{ijk} = 0
\end{array}\right.
\end{align*}

### Update $\beta_{k}$:

Let $\bar{\mathbf{Z}}_{ijk} = \mathbf{Z}_{ijk} - a_{ik} - b_{jk} - u_{ik}^Tv_{jk}$

\begin{align*}
\text{Pr}(\bar{\mathbf{Z}}_{ijk}) &\propto \prod_{i \neq j}^{n_k}\exp\Bigg(-\frac{1}{2} \begin{pmatrix} \bar{\mathbf{Z}}_{ijk} - \sum_{p}\mathbf{X}_{ijpk}\beta_{pk}\\ \bar{\mathbf{Z}}_{jik} - \sum_{p}\mathbf{X}_{jipk}\beta_{pk} \end{pmatrix}^T \mathbf{\Sigma}_{\rho}^{-1} \begin{pmatrix} \bar{\mathbf{Z}}_{ijk} - \sum_{p}\mathbf{X}_{ijpk}\beta_{pk}\\ \bar{\mathbf{Z}}_{jik} - \sum_{p}\mathbf{X}_{jipk}\beta_{pk}  \end{pmatrix}\Bigg)\\%\cdot \text{dNorm}(\beta_k; \mu, \sigma^2)\\
\therefore \text{Pr}(\bar{\mathbf{Z}}_{ijk}\mid \bar{\mathbf{Z}}_{jik}) &\sim N(\sum_{p}\mathbf{X}_{ijpk}\beta_{pk} + \rho_k(\bar{\mathbf{Z}}_{jik}- \sum_{p}\mathbf{X}_{jipk}\beta_{pk}), 1-\rho_k^2)\\
&\propto \prod_{i \neq j} \exp\Bigg(-\frac{1}{2}\Big(\bar{Z}_{ijk} - \rho_k\sum_{p}\mathbf{X}_{jipk})\beta_{pk} - \rho_k(\bar{Z}_{jik} - X_{jik}\beta_k)\Big)^2 \cdot (1 - \rho_k^2)^{-1}\Bigg)\\
\therefore \text{Pr}(\beta_k \mid  \mathbf{Z}_k) &\propto \prod_{i \neq j} \exp\Bigg(-\frac{1}{2} \Big( (X_{ijk} - \rho_k \sum_{p}\mathbf{X}_{jipk})\beta_{pk} - \bar{Z}_{ijk} - \rho_k \bar{Z}_{jik} \Big)^2 \cdot (1-\rho_k^2)^{-1}\Bigg) \cdot \text{dN}(\beta_k; \mu, \mathbf{\Sigma}_{\beta})\\
&\propto 
\exp{\Bigg(-\frac{1}{2}}(1-\rho_k^2)^{-1} \Big(\mathbf{\Theta}_{\beta} \vec{\beta}_k - \text{vec}(\mathbf{Z}_{k}) + \rho_k \text{vec}(\mathbf{Z}^T_{k})\Big)^T \Big(\mathbf{\Theta}_{\beta} \vec{\beta}_k - \text{vec}(\mathbf{Z}_{k}) + \rho_k \text{vec}(\mathbf{Z}^T_{k})\Big)\Bigg)\\
&\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\, \times \exp{\Bigg(-\frac{1}{2}(\vec{\beta_k}-\vec{\mu})^T\mathbf{\Sigma}_\beta^{-1}(\vec{\beta_k}-\vec{\mu})\Bigg)}\\
\end{align*} where $\mathbf{\Theta}_{\beta}$ is a vector length of $n(n-1)$, and, $$\mathbf{\Theta}_{\beta} = \Big(\begin{pmatrix}  | & \cdots & | \\ \text{vec}(\mathbf{X}_{1k}) & \cdots  &\text{vec}(\mathbf{X}_{Pk}) \\ | & \cdots & |\end{pmatrix} - \rho_k \begin{pmatrix}  | & \cdots & | \\ \text{vec}(\mathbf{X}^T_{1k}) & \cdots  &\text{vec}(\mathbf{X}^T_{Pk}) \\ | & \cdots & |\end{pmatrix} \Big)$$ Thus, we have $\mathbf{V}_n = \mathbf{A}_n^{-1}$ where $\mathbf{A}_n = \mathbf{A}_0 + \mathbf{A}_1$, and $\mathbf{A}_0 = \mathbf{\Sigma}_{\beta}^{-1}$, $\mathbf{A}_1 = (1-\rho_k^2)^{-1}\mathbf{\Theta}_{\beta}^{T}\mathbf{\Theta}_{\beta}$

$\mu_n = \mathbf{V}_nm_n$ where $m_n = m_0 + m_1$, and $m_0 = \mathbf{\Sigma}_{\beta}^{-1}\mu$ and $m_1 = (1-\rho_k^2)^{-1}\mathbf{\Theta}_{\beta}^{T}\Big(\text{vec}(\mathbf{Z}_k) - \rho_k\text{vec}(\mathbf{Z}_k^T)\Big)$

### Update $a_i,b_i$:

Let $\hat{\mathbf{Z}}_{ijk} = \mathbf{Z}_{ijk} - \sum_{p}\mathbf{X}_{ijpk}\beta_{pk} - u_{ik}^Tv_{jk}$

\begin{align*}
\text{Pr}\Bigg(\begin{pmatrix}a_{ik} \\ b_{ik}\end{pmatrix} \mid \begin{pmatrix} \hat{Z}_{ijk}\\ \hat{Z}_{jik} \end{pmatrix}, \dots\Bigg) &\propto \\ & \prod_{i \neq j}^{n_k}\exp\Bigg(-\frac{1}{2} \begin{pmatrix} \hat{Z}_{ijk} - a_{ik} - b_{jk}\\ \hat{Z}_{jik} - a_{jk}-b_{ik} \end{pmatrix}^T \Sigma_{\rho}^{-1} \begin{pmatrix} \hat{Z}_{ijk}-a_{ik}-b_{jk}\\ \hat{Z}_{jik}-a_{jk}-b_{ik} \end{pmatrix}\Bigg)\cdot \text{dMVN}_2\Bigg(\begin{pmatrix}a_{ik} \\ b_{ik}\end{pmatrix}; \begin{pmatrix} 0\\ 0\end{pmatrix}, \Sigma_{ab}\Bigg)\\
\therefore \text{Pr}(\hat{\mathbf{Z}}_{ijk}\mid \hat{\mathbf{Z}}_{jik}) &\sim N(a_{ik} - (-b_{jk} - \rho_k(\hat{\mathbf{Z}}_{jik} - a_{jk} - b_{ik})), 1-\rho_k^2)\\
\therefore \text{Pr}(a_{ik}\mid \mathbf{Z}_k) &\propto
\prod_{j \neq i}\exp\Bigg(-\frac{1}{2}(1- \rho_k^2)^{-1}(\hat{\mathbf{Z}}_{ijk} - a_{ik} - b_{jk} - \rho_k(\hat{\mathbf{Z}}_{jik} - a_{jk} - b_{ik}))^2\Bigg)\\
& \,\,\,\,\,\,\,\,\,\,\,\, \cdot \text{dN}(a_{ik}\mid b_{ik}\,\, ; \,\, \mu_{a\mid b} = \mathbf{\Sigma}_{ab[1,2]}\mathbf{\Sigma}_{ab[2,2]}^{-1}b_{ik}, \,\, \sigma^2_{a\mid b} = \mathbf{\Sigma}_{ab[1,1]}-\mathbf{\Sigma}_{ab[1,2]}\mathbf{\Sigma}_{ab[2,2]}^{-1}\mathbf{\Sigma}_{ab[2,1]})\\
&\propto \exp\Bigg(-\frac{1}{2}(1-\rho_k)^{-1}\sum_{j \neq i}(a_{ik} - \theta_{j})^{T}(a_{ik} - \theta_{j})\Bigg) \cdot \exp \Bigg(-\frac{1}{2}(a_{ik} - \mu_{a\mid b})^2 \sigma^{-2}_{a\mid b}\Bigg)\end{align*}

$\text{where } \theta_{j} = -b_{jk} - \rho_k(\hat{\mathbf{Z}}_{jik} - a_{jk} - b_{ik}) + \hat{\mathbf{Z}}_{ijk}$ and $i$ is fixed. Then, we can easily figure out its posterior mean and variance.

$\mathbf{V}_n = \mathbf{A}_n^{-1} \text{ where } \mathbf{A}_n = \mathbf{A}_0 + \mathbf{A}_1, \text{ and } \mathbf{A}_0 = \sigma^{-2}_{a\mid b}, \mathbf{A}_1 = (n_k - 1)(1-\rho_k^2)^{-1}$

$\mu_n = \mathbf{V}_nm_n$ where $m_n = m_0 + m_1$, and $m_0 = \sigma_{a\mid b}^{-2}\mu_{a\mid b}$ and $m_1 = (1-\rho_k^2)^{-1}\sum_{j\neq i}{\theta}_{j}$

\noindent Likewise, we can update $b_{ik}$.

### Update $u_i, v_i$

Let $\tilde{Z}_{ijk} = Z_{ijk} - X_{ijk}\beta_k - a_{ik} - b_{jk}$ \begin{align*}
p\Bigg(\begin{pmatrix}u_{ik} \\ v_{ik}\end{pmatrix} \mid  \begin{pmatrix} \tilde{Z}_{ijk}\\ \tilde{Z}_{jik} \end{pmatrix},\dots \Bigg) &\propto\\ &\prod_{i \neq j}^{n_k}\exp\Bigg(-\frac{1}{2} \begin{pmatrix} \tilde{Z}_{ijk} - u_{ik}^Tv_{jk}\\ \tilde{Z}_{jik} - u_{ik}^Tv_{jk} \end{pmatrix}^T \Sigma_{\rho}^{-1} \begin{pmatrix} \tilde{Z}_{ijk}-u_{ik}^Tv_{jk}\\ \tilde{Z}_{jik}-u_{ik}^Tv_{jk} \end{pmatrix}\Bigg)\cdot \text{dMVN}_4\Bigg(\begin{pmatrix}u_{ik} \\ v_{ik}\end{pmatrix}; \begin{pmatrix} 0\\ 0\\0\\0\end{pmatrix}, \Sigma_{uvk}\Bigg)\\
\therefore \text{Pr}(\tilde{Z}_{ijk}\mid \tilde{Z}_{jik}) &\sim \text{N}(u_{ik}^Tv_{jk} + \rho_k(\tilde{Z}_{jik}- u_{jk}^Tv_{ik}), 1-\rho_k^2)\\
\therefore \text{Pr}(u_{ik}\mid \tilde{Z}_k) &\propto \prod_{j \neq i}\exp\Bigg(-\frac{1}{2}(1-\rho_k^2)^{-1}(\tilde{Z}_{ijk} - u_{ik}^Tv_{jk} - \rho_k(\tilde{Z}_{jik}-u_{jk}^Tv_{ik}))^2\Bigg)\\
& \,\,\,\,\,\,\,\,\,\, \text{dMVN}_2(u_{ik}\mid v_{ik} \,\, ; \,\, \mu_{u\mid v} = \Sigma_{uv[1,2]}\Sigma_{uv[2,2]}^{-1}v_{ik}, \,\, \Sigma_{u\mid v} = \Sigma_{uv[1,1]} - \Sigma_{uv[1,2]}\Sigma_{uv[2,2]}^{-1} \Sigma_{uv[2,1]})\\
&\propto \exp\Bigg(-\frac{1}{2}(1-\rho_k^2)^{-1}(\mathbf{\Theta}_{V}u_{ik}- \vec{\mu}_u)^T (\mathbf{\Theta}_{v}u_{ik}- \vec{\mu}_u)\Bigg) \cdot \exp\Bigg(-\frac{1}{2}(u_{ik}-\mu_{u\mid v})^T\Sigma_{u\mid v}(u_{ik}-\mu_{u\mid v})\Bigg)\\
\text{Where } &\mathbf{\Theta}_{V} = \begin{pmatrix}  | & | \\ \vec{v}_{jk[-i,1]} & \vec{v}_{jk[-i,2]}   \\ | & |\end{pmatrix} \text{ ,and } \vec{\mu}_u = \begin{pmatrix} | \\ \tilde{Z}_{i,\cdot,k} - \rho_k(\tilde{Z}_{\cdot,i,k} - u_{\cdot}^{T}v_{i})\\ | \end{pmatrix}\\
&\text{, and dimensions are }(n_k-1)\times 2 \text{and } (n_k-1)\times 1, \text{respectively.}\\
\end{align*} Then, we have $\mathbf{V}_n = \mathbf{A}_n^{-1} \text{ where } \mathbf{A}_n = \mathbf{A}_0 + \mathbf{A}_1, \text{ and } \mathbf{A}_0 = \Sigma^{-1}_{u\mid v}, \mathbf{A}_1 = (1-\rho_k^2)^{-1}\mathbf{\Theta}_{V}^T\mathbf{\Theta}_{V}$

$\mu_n = \mathbf{V}_nm_n$ where $m_n = m_0 + m_1$, and $m_0 = \Sigma_{u\mid v}^{-1}\mu_{u\mid v}$ and $m_1 = (1-\rho_k^2)^{-1}\mathbf{\Theta}_{V}^T\vec{\mu}_u$.

### Update $\rho_k$

Let $\tilde{\epsilon}_{ijk} = Z_{ijk} - X_{ijk}\beta_k - a_{ik} - b_{jk}-  u_{ik}^Tv_{jk}$

\begin{align*}
p\Bigg(\rho_k\mid  \begin{pmatrix} \tilde{\epsilon}_{ijk}\\ \tilde{\epsilon}_{jik} \end{pmatrix},\dots \Bigg) &\propto \prod_{i \neq j}^{n_k}\exp\Bigg(-\frac{1}{2} \begin{pmatrix} \tilde{\epsilon}_{ijk}\\ \tilde{\epsilon}_{jik}\end{pmatrix}^T \Sigma_{\rho}^{-1} \begin{pmatrix} \tilde{\epsilon}_{ijk}\\ \tilde{\epsilon}_{jik} \end{pmatrix}\Bigg)\cdot \text{dUnif}(\rho_k; -1, 1)
\end{align*} To update $\rho_k$, Metropolis-Hastings is needed due to non-conjugacy.

### Update $\mu$ 

\begin{align*}
p(\mu\mid \vec{Y}, \dots) &\propto \prod_{k=1}^{K}\text{dNorm}(\beta_{k}; \mu, \sigma) \cdot \text{dNorm}(\mu;\lambda,\tau)\\
&\sim \text{N}\left(\mu; \frac{\lambda/\tau + \sum_{k}\beta_{k}/\sigma^2}{(1\tau + K/\sigma^2)}, (1/\tau + K/\sigma^2)^{-1}\right)
\end{align*}

### Update $\sigma^2$

\begin{align*}
p(\sigma^2\mid \vec{Y}, \dots) &\propto \prod_{k=1}^{K}\text{dNorm}(\beta_{k}; \mu, \sigma) \cdot \text{dIG}(\sigma^2;\nu_0,S_0)\\
&\sim \text{IG}\left(\sigma^2; \frac{\nu_0 + K}{2}, \frac{\nu_0 \cdot S_0 + \sum_k(\beta_{k}-\mu)^2}{2}\right)
\end{align*}

### Update $\Sigma_{ab}$:

\begin{align*}
p(\Sigma_{abk}\mid \vec{Y}, \dots) &\propto \prod_{i=1}^{n_k}\text{dMVN}\Bigg(\begin{pmatrix} a_{ik}\\ b_{ik}\end{pmatrix}; \vec{0}, \Sigma_{ab}\Bigg) \cdot \text{dIWishart}(\Sigma_{ab};\nu_{ab} ,S_{abk}^{-1})\\
&\sim \text{IWishart}\left(\Sigma_{abk}; \nu_{ab} + n_k,\left[S_{ab} + \sum_{i=1}^{n_k}\begin{pmatrix} a_{ik}\\ b_{ik}\end{pmatrix}\begin{pmatrix} a_{ik}\\ b_{ik}\end{pmatrix}^T\right]^{-1}\right)
\end{align*}

### Update $\Sigma_{uv}$

\begin{align*}
p(\Sigma_{uvk}\mid \vec{Y}, \dots) &\propto \prod_{i=1}^{n_k}\text{dMVN}\Bigg(\begin{pmatrix} u_{ik}\\ v_{ik}\end{pmatrix}; \vec{0}, \Sigma_{uv}\Bigg) \cdot \text{dIWishart}\left(\Sigma_{uvk};\nu_{uv} ,S_{uv}^{-1}\right)\\
&\sim \text{IWishart}\left(\Sigma_{uvk}; \nu_{uv} + n_k,\left[S_{uv} + \sum_{i=1}^{n_k}\begin{pmatrix} u_{ik}\\ v_{ik}\end{pmatrix}\begin{pmatrix} u_{ik}\\ v_{ik}\end{pmatrix}^T\right]^{-1}\right)
\end{align*}

## Coding (Temporary)

For the following function, two main arguments are required: data and edge_covariate. Both arguments should follow a list format. For now, the argument, edge_covariate, takes only one edge-specific covariate.

```{r}
hsvd = function(data, edge_covariate, dyad_dep = T, num_iter = 1000, verbose = T, hier = T){

  suppressMessages(require(tmvtnorm))
  suppressMessages(require(mvtnorm))
  suppressMessages(require(truncnorm))
  suppressMessages(require(MCMCpack))

  iternum = num_iter
  Y = data
  COV = edge_covariate
  K = length(Y)
  nk = unlist(lapply(Y, nrow))
  
   # Create a list to collect MCMC samples
    Chain = list("beta" = list(), 
                 "rho" = matrix(nrow=iternum, ncol=K), 
                 "sigma_ab" = list(), "sigma_uv" = list(),
                 "U" = list(), "V" = list(), 
                 "a" = list(), "b" = list(), 
                 "z" = list(), "mu" = matrix(nrow=iternum, ncol=2),
                 "s2" = matrix(nrow=iternum, ncol=2))
    
    for (i in 1:K){
      Chain$U[[i]] = Chain$V[[i]] = list()
      for (j in 1:iternum){
        Chain$U[[i]][[j]] = Chain$V[[i]][[j]] = list()
      }
      Chain$beta[[i]] = matrix(nrow=iternum,ncol=2)
      Chain$a[[i]] = Chain$b[[i]] = matrix(nrow=iternum, ncol=nk[i])
    }
    
    # Initial points for parameters
    {
      beta0 = rep(0,K)
      beta1 = rep(0,K)
      beta = cbind(beta0,beta1)
      mu0 = mu = 0
      s02 = s2 = 1
      # sigma_uv
      sigma_uv =  matrix(0.5,4,4)
      diag(sigma_uv) = 1
      
      # Random Initial points for U and V
      U = V = list()
      for (i in 1:K){
        U[[i]] = as.matrix(rmvnorm(nk[i],c(0,0),sigma_uv[1:2,1:2]),ncol=2)
        V[[i]] = as.matrix(rmvnorm(nk[i],c(0,0),sigma_uv[3:4,3:4]),ncol=2)
      }
      
      
      # Create Starting points for z, a, b
      z = a = b = list()
      
      # sigma_ab
      sigma_ab = matrix(c(1,0.5,0.5,1),2,2) 
      
      # fill in z,a,b with random numbers
      for (k in 1:K){
        z[[k]] = matrix(rnorm(nk[k]*nk[k]), ncol=nk[k],nrow=nk[k])
        diag(z[[k]]) = NA
        a[[k]] = b[[k]] = numeric(nk[k])
      }
      
      #initial for rho, beta0, beta1
      if (dyad_dep == T){
        rho = rep(0.5,K)
      } else rho = rep(0,K)
    }
  
  
  #MCMC
    
  ptm <- proc.time()
    for (k in 1:K){
      diag(Y[[k]]) = 0
      diag(Cov1[[k]]) = 0
      diag(z[[k]]) = 0 
    }
    
    for (sim in (1):(iternum)){
      
      for (k in 1:K){
        index = which(diag(nk[k]) == 1)
        
        ### Update Z ###
        etas = matrix(cbind(1,c(Cov1[[k]])) %*% beta[k,] +
                        rowSums(U[[k]][rep(seq_len(nrow(U[[k]])), nk[k]),] *
                                  V[[k]][rep(seq_len(nrow(V[[k]])), each=nk[k]),]) +
                        rep(a[[k]], nk[k]) +
                        rep(b[[k]], each=nk[k]),
                      nk[k],nk[k])
        
        diag(etas) = 0
        
        m = c(etas) + rho[k]*( c(t(z[[k]])) - c(t(etas)))
        
        z[[k]] = matrix(rtruncnorm(1,
                                   a = ifelse(c(Y[[k]]), 0, -Inf),
                                   b = ifelse(c(Y[[k]]), Inf, 0),
                                   mean = m, sd = sqrt(1-rho[k]^2)),
                        nrow = nk[k], ncol = nk[k])
      
        ### Update beta0, beta1 ###
        sigma_beta = matrix(c(s02,0,0,s2),2,2)
        
        zbar = matrix(
          c(z[[k]])-
            rep(a[[k]], nk[k]) - 
            rep(b[[k]], each=nk[k]) - 
            rowSums(U[[k]][rep(seq_len(nrow(U[[k]])), nk[k]),] *
                      V[[k]][rep(seq_len(nrow(V[[k]])), each=nk[k]),]),
          nk[k],nk[k])
        
        diag(zbar) = 0
        rp = 1 / (1-rho[k]^2)
        X = (cbind(1,c(Cov1[[k]])) - rho[k]*(cbind(1, c(t(Cov1[[k]])))))[-index,]
        
        V_beta = solve( solve(sigma_beta) + rp*crossprod(X))
        
        mu_beta = V_beta %*% ( solve(sigma_beta) %*% c(mu0,mu) 
                               + rp * crossprod(X, c(zbar)[-index] - rho[k] * c(t(zbar))[-index]))
        
        beta[k,] = rmvnorm(1, mu_beta, V_beta)
        
        ### Update a, b ###
        zhat = matrix( c(z[[k]]) -
                         c(cbind(1, c(Cov1[[k]]))%*%beta[k,]) -
                         rowSums(U[[k]][rep(seq_len(nrow(U[[k]])), nk[k]),] *
                                   V[[k]][rep(seq_len(nrow(V[[k]])), each=nk[k]),]),
                       nk[k], nk[k])
        
        S11 = sigma_ab[1,1]; S22 = sigma_ab[2,2]; S12 = S21 = sigma_ab[1,2]
        
        sigma2_a = S11 - S12%*% solve(S22) %*% S21
        sigma2_b = S22 - S21%*% solve(S11) %*% S12
        
        for (i in sample(1:nk[k])){
          theta_ai = sum(zhat[i,-i] - rho[k]*(zhat[-i,i] - a[[k]][-i] - b[[k]][i]) - b[[k]][-i])
          
          m_ab = S12%*%solve(S22)%*%b[[k]][i]
          
          A0 = 1/sigma2_a; A1 = (nk[k]-1) * rp
          m0 = 1/sigma2_a*m_ab; m1 = rp * theta_ai
          
          mu_ai = 1/(A0+A1)*(m0+m1)
          s2_ai = 1/(A0+A1)
          a[[k]][i] = rnorm(1, mu_ai, sqrt(s2_ai))
          
          
          theta_bi = sum(zhat[-i,i] - rho[k]*(zhat[i,-i] - b[[k]][-i] - a[[k]][i]) - a[[k]][-i])
          m_ba = S21%*%solve(S11)%*%a[[k]][i]
          A0 = 1/sigma2_b; A1 = (nk[k]-1) * rp
          m0 = 1/sigma2_b*m_ba; m1 = rp * theta_bi
          
          mu_bi = 1/(A0+A1)*(m0+m1)
          s2_bi = 1/(A0+A1)
          b[[k]][i] = rnorm(1, mu_bi, sqrt(s2_bi))
        }
        
  
        ### Update U, V ###

        ztilde = matrix( c(z[[k]]) -
                           cbind(1, c(Cov1[[k]]))%*%beta[k,] -
                           rep(a[[k]], nk[k]) - rep(b[[k]], each=nk[k]),
                         nk[k], nk[k])
        
        diag(ztilde) = 0
        
        S11 = sigma_uv[1:2,1:2]; S22 = sigma_uv[3:4,3:4]; S12 = sigma_uv[1:2,3:4]; S21 = sigma_uv[3:4,1:2]
        
        sigma2_u = S11 - S12%*% solve(S22) %*% S21
        sigma2_v = S22 - S21%*% solve(S11) %*% S12
        
        for (i in sample(1:nk[k])){
          Theta_V = V[[k]][-i,]
          mu_u = ztilde[i,-i] - c(rho[k]*(ztilde[-i,i] - U[[k]][-i,] %*% V[[k]][i,]))
          
          mu_uv = S12%*%solve(S22)%*%V[[k]][i,]
          
          A0 = solve(sigma2_u); A1 = rp*crossprod(Theta_V)
          
          m0 = solve(sigma2_u)%*%mu_uv; m1 = rp*crossprod(Theta_V,mu_u)
          
          mu_ui = solve(A0+A1)%*%(m0+m1)
          
          U[[k]][i,] = mvrnorm(1,mu_ui,solve(A0+A1))
          
          Theta_U = U[[k]][-i,]
          mu_v = ztilde[-i,i] - c(rho[k]*(ztilde[i,-i] - V[[k]][-i,] %*% U[[k]][i,]))
          
          mu_vu = S21%*%solve(S11)%*%U[[k]][i,]
          
          A0 = solve(sigma2_v); A1 = rp*crossprod(Theta_U)
          m0 = solve(sigma2_v)%*%mu_vu; m1 = rp*crossprod(Theta_U,mu_v)
          mu_vi = solve(A0+A1)%*%(m0+m1)
          
          V[[k]][i,] = mvrnorm(1,mu_vi,solve(A0+A1))
        }
        
        
        
        ### Update rho ###
        if (dyad_dep == T){
        etilde = matrix(c(z[[k]]) -
                          cbind(1, c(Cov1[[k]]))%*%beta[k,] -
                          rep(a[[k]], nk[k]) - rep(b[[k]], each=nk[k]) -
                          rowSums(U[[k]][rep(seq_len(nrow(U[[k]])), nk[k]),] * 
                                  V[[k]][rep(seq_len(nrow(V[[k]])), each=nk[k]),]),
                        nk[k],nk[k])
        diag(etilde) = 0
        EM<-cbind(etilde[upper.tri(etilde)],t(etilde)[upper.tri(etilde)] )
        emcp<-sum(EM[,1]*EM[,2])
        emss<-sum(EM^2)
        m<- nrow(EM)
        
        sr = 2 * (1-cor(etilde)[1,2]^2)/sqrt(m)
        
        rho_p = rho[k] + sr * qnorm( runif(1,pnorm( (-1-rho[k])/sr), pnorm( (1-rho[k])/sr)))

        rd <- (-.5*(m*log(1-rho_p^2)+(emss-2*rho_p*emcp)/(1-rho_p^2)))-
          (-.5*(m*log(1-rho[k]^2 )+(emss-2*rho[k]*emcp )/(1-rho[k]^2 )))+
          ( (-.5*log(1-rho_p^2)) - (-.5*log(1-rho[k]^2)) )
        
        
        if (log(runif(1)) < rd) rho[k] = rho_p
        }
        
        Chain$rho[sim,k] = rho[k]
        Chain$beta[[k]][sim,] = beta[k,]
        Chain$U[[k]][[sim]] = U[[k]]
        Chain$V[[k]][[sim]] = V[[k]]
        Chain$a[[k]][sim,] = a[[k]]
        Chain$b[[k]][sim,] = b[[k]]
      }
      
      if (hier == T){
        ### Update Sigma_ab ###
        Sab0 = matrix(c(1,0,0,1),ncol=2); nuab0 = 2+2
        S_theta_ab = matrix(rowSums(apply(do.call(rbind,Map(cbind,a,b)) ,1,tcrossprod)),2,2)
        sigma_ab = riwish(v = nuab0 + sum(nk) , S = Sab0 + S_theta_ab)
        
        ### Update Sigma_uv ###
        Suv0 = matrix(c(rep(5,16)),ncol=4); diag(Suv0) = 10; nuuv0 = 4+2
        S_theta_uv = matrix(rowSums(apply(do.call(rbind,Map(cbind,U,V)),1,tcrossprod)),4,4)
        sigma_uv = riwish(v =nuuv0 + sum(nk), S= Suv0 + S_theta_uv)
        
        ### Update mu0 (mean of beta0) ###
        s00 = 1; mu00 = 0
        s02_n= (1/s00 + (K / s02))^(-1)
        mu0_n= (mu00 / s00 + sum(beta[,1]) / s02) * s02_n
        mu0 = rnorm(1, mu0_n, sqrt(s02_n)) 
        
        ### Update mu (mean of beta1) ###
        s10 = 1; mu10 = 0
        s2_n= (1/s10 + (K / s2))^(-1)
        mu_n= (mu10 / s10 + sum(beta[,2]) / s2) * s2_n
        mu = rnorm(1, mu_n, sqrt(s2_n))
        
        ### Update S0 (var of beta0) ###
        c = 5; d = 0.25  # Hyperparameters
        
        nu0_n = c + K
        ss0_n = 1/nu0_n * (c * d + (K-1)*var(beta[,1]) + K/(K+1)*(mean(beta[,1])-mu0)^2)
        s02 = 1/ rgamma(1, nu0_n/2, nu0_n*ss0_n/2)
        
        ### Update S1 (var of beta1) ###
        nu_n = c + K
        ss_n = 1/nu_n * (c * d + (K-1)*var(beta[,2]) + K/(K+1)*(mean(beta[,2])-mu)^2)
        s2 = 1/ rgamma(1, nu_n/2, nu_n*ss_n/2)
        
        Chain$sigma_ab[[sim]] = sigma_ab
        Chain$sigma_uv[[sim]] = sigma_uv
        Chain$mu[sim,] = cbind(mu0,mu)
        Chain$s2[sim,] = cbind(s02,s2)
      }
        

      if (sim %% 100 == 0 & verbose == T) {
        ptm2 = (proc.time() - ptm)[3]
        cat(sim,"/",iternum,"   (time:", ptm2, ")", 
            "     (estimated time left:", ptm2*(iternum-sim)/100, ") \n")
        ptm = proc.time()
      }
    }
    return(Chain)
}
```

## Test (with simulated data)

```{r}
# 2 networks with sizes of 20 and 60. suppressMessages(library(mvtnorm))

K = 2 
Cov1 = list() 
nk = c(20, 60)

set.seed(1)

for (i in 1:K){ 
  Cov1[[i]] = matrix(rnorm(nk[i]^2),nk[i],nk[i]) 
  diag(Cov1[[i]]) = NA 
}
```

The simulated dataset has 6 networks: Network 1 is the smallest one with 5 nodes, and the other 5 networks have 20 nodes. As discussed previously, we can expect shrinkage effect by hierarchical modeling and smaller variance in parameter estimation for Network 1. The plot above displays 95 percentiles of $\beta_1$s for each network and the blue dashed lines are the true value. Given the assumption that there truely exists hierarchical structure, the individual network analysis not only misses some of the true $\beta_1$s, but also larger variance for small network. Furthermore, given that all mean posterior estimates of networks in hierarchical model have much more similar values than those in individual model, we can easily conclude that the shrinkage exists.

## Discussion

The hierarhical network modeling allows one obtain more stable parameter estimations by adding the assumption that the parameters for each network are generated by some hyperparameters. This assumption is plausible because the networks in a dataset may behave similarly each other. For example, in educational research settings, networks of multiple schools are usually collected, and it is reasonable to consider the schools are somehow conneted each other and the actors of each school behave similarly. And hierarchical network analysis allows one make the connection of those networks.

For further research, the computation speed should be optimized by parallel computing or vectorization. Moreover, with dyadic dependence, $\rho$, every Gibbs sampler simulation was done by fixing the other element. This may lead to bad mixing in MCMC with high autocorrelation. So it would be much faster and nicer in mixing if the MCMC can be done with the joint distribution itself.
